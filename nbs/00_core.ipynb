{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00_core\n",
    "\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import base64\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import pytest\n",
    "import yaml\n",
    "from bs4 import BeautifulSoup\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "from icecream import ic\n",
    "from loguru import logger as lg\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "PKG_DIR = pkg_resources.resource_filename(__name__, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | export\n",
    "ic.configureOutput(outputFunction=lambda x: lg.info(x), prefix=\"\")\n",
    "try:\n",
    "    lg.remove(0)\n",
    "except:\n",
    "    pass\n",
    "lg.add(\"harmony_automation.log\", format=\"{time} | {level} | {message}\", level=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 init fxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def fp(relative_fp: str, base_dir: str = PKG_DIR) -> str:\n",
    "    \"\"\"If imported, pkg dir == `pkg/pkg` and relative paths are the same as in notebook env. Need to adjust when running `nbdev_docs`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    relative_fp : str\n",
    "        str - eg. \"../dir/file.txt\"\n",
    "    base_dir : str, optional\n",
    "        str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        str\n",
    "    \"\"\"\n",
    "    docs_mode = not os.path.exists(os.path.join(base_dir, relative_fp))\n",
    "\n",
    "    if docs_mode:\n",
    "        relative_fp = relative_fp.replace(\"..\", \".\", 1)\n",
    "\n",
    "    return os.path.join(base_dir, relative_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def return_yaml_data(file_path: str) -> dict:\n",
    "    \"\"\"...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        dict\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = yaml.safe_load(f.read())\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "CFG = return_yaml_data(fp(\"../cfg/config.yaml\"))\n",
    "serv = Service(executable_path=CFG[\"chromedriver\"])\n",
    "driver = webdriver.Chrome(service=serv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 find xpath elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# * FINAL\n",
    "def search_for_xpath_elem(xpath_str: str, time_limit: int = 30) -> list:\n",
    "    \"\"\"While len of search list is 0, keep searching. If exceeds time limit (seconds, approximate),  returns empty list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xpath_str : str\n",
    "        str\n",
    "    time_limit : int, optional\n",
    "        int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List[WebElement]\n",
    "    \"\"\"\n",
    "    ctr = 0\n",
    "    t_search = driver.find_elements(By.XPATH, xpath_str)\n",
    "\n",
    "    while (len(t_search) == 0) and (ctr < time_limit):\n",
    "        time.sleep(1)\n",
    "        ctr += 1\n",
    "        t_search = driver.find_elements(By.XPATH, xpath_str)\n",
    "\n",
    "    if len(t_search) > 0:\n",
    "        return t_search\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# * FINAL\n",
    "def return_data() -> pd.DataFrame:\n",
    "    \"\"\"Load and clean one of the output files created from the update script - `for_log_tracker_...xlsx`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    latest = sorted(os.listdir(fp(\"../dat\")))[-1]\n",
    "    print(latest)\n",
    "\n",
    "    df = pd.read_excel(fp(f\"../dat/{latest}\"))\n",
    "    df = df[[\"ticket_num\", \"death_update\"]].copy()\n",
    "    df.columns = [\"ticket_num\", \"log_action\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 harmony specific actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# * FINAL\n",
    "def login() -> None:\n",
    "    \"\"\"Log in to Harmony\"\"\"\n",
    "    driver.get(CFG[\"url\"])\n",
    "\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"username_xpath\"))\n",
    "    t_search[0].send_keys(CFG[\"user\"])\n",
    "\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"password_xpath\"))\n",
    "    t_search[0].send_keys(CFG[\"pass\"])\n",
    "    time.sleep(1)\n",
    "    t_search[0].send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "def search_ticket_num(ticket_num: str) -> None:\n",
    "    \"\"\"Go to ticket number search page and search for `ticket_num`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ticket_num : str\n",
    "        str\n",
    "    \"\"\"\n",
    "    # click search by ticket number\n",
    "    time.sleep(1)\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"log_search_xpath\"))\n",
    "    time.sleep(0.5)\n",
    "    t_search[0].click()\n",
    "\n",
    "    # refresh\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"refresh_btn_xpath\"))\n",
    "    time.sleep(1)\n",
    "    t_search[0].click()\n",
    "\n",
    "    # input ticket number\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"tkt_num_input_xpath\"))\n",
    "    time.sleep(1)\n",
    "    t_search[0].send_keys(str(ticket_num))\n",
    "\n",
    "    # click search\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"tkt_num_button_xpath\"))\n",
    "    time.sleep(1)\n",
    "    t_search[0].click()\n",
    "\n",
    "\n",
    "def view_log() -> None:\n",
    "    \"\"\"Clicks `view log` of search result\"\"\"\n",
    "    # there should only be one result\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"result_actions_xpath\"))\n",
    "    time.sleep(1)\n",
    "    t_search[0].click()\n",
    "\n",
    "    # view log\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"view_log_btn_xpath\"))\n",
    "    time.sleep(1)\n",
    "    t_search[0].click()\n",
    "\n",
    "\n",
    "def click_edit_log() -> None:\n",
    "    \"\"\"Clicks `edit` button\"\"\"\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"log_edit_btn_xpath\"))\n",
    "    time.sleep(1)\n",
    "    t_search[0].click()\n",
    "\n",
    "\n",
    "def edit_res(comment=\"done\") -> None:\n",
    "    \"\"\"Add `comment` to resolution input box\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    comment : str, optional\n",
    "        str\n",
    "    \"\"\"\n",
    "    # xpath for resolution input differs by log type\n",
    "    xpath_list = CFG.get(\"resolution_input_xpath_list\")\n",
    "    t_search = []\n",
    "    while len(t_search) == 0:\n",
    "        for xpath_str in xpath_list:\n",
    "            t_search = driver.find_elements(By.XPATH, xpath_str)\n",
    "            try:\n",
    "                t_search[0].send_keys(comment)\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                t_search = [0]\n",
    "                break\n",
    "\n",
    "\n",
    "def submit_res() -> None:\n",
    "    \"\"\"Clicks `submit`\"\"\"\n",
    "    # xpath for submit button differs by log type\n",
    "    xpath_list = CFG.get(\"submit_btn_xpath_list\")\n",
    "    t_search = []\n",
    "    while len(t_search) == 0:\n",
    "        for xpath_str in xpath_list:\n",
    "            t_search = driver.find_elements(By.XPATH, xpath_str)\n",
    "            try:\n",
    "                t_search[0].click()\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                t_search = [0]\n",
    "                break\n",
    "\n",
    "\n",
    "def reassign_log(note: str) -> None:\n",
    "    \"\"\"Actions to execute on ticket number search results page\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    note : str\n",
    "        str\n",
    "    \"\"\"\n",
    "    # there should only be one result\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"result_actions_xpath\"))\n",
    "    time.sleep(0.5)\n",
    "    t_search[0].click()\n",
    "\n",
    "    # click re-assign\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"reassign_btn_xpath\"))\n",
    "    time.sleep(0.5)\n",
    "    t_search[0].click()\n",
    "\n",
    "    # enter name\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"search_user_xpath\"))\n",
    "    time.sleep(0.5)\n",
    "    t_search[0].send_keys(CFG.get(\"colleague\"))\n",
    "    time.sleep(0.3)\n",
    "    t_search[0].send_keys(Keys.RETURN)\n",
    "\n",
    "    # click assign button\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"assign_btn_xpath\"))\n",
    "    time.sleep(0.3)\n",
    "    t_search[0].click()\n",
    "\n",
    "    # enter reason\n",
    "    t_search = search_for_xpath_elem(CFG.get(\"reason_input_xpath\"))\n",
    "    time.sleep(0.5)\n",
    "    t_search[0].send_keys(note)\n",
    "\n",
    "    # submit reason\n",
    "    time.sleep(1.5)\n",
    "    submit_reason_xpath = CFG.get(\"submit_reason_xpath\")\n",
    "    t_search = driver.find_elements(By.XPATH, submit_reason_xpath)\n",
    "    t_search[0].click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 scrape fxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# * FINAL\n",
    "def test_page_source_ok(page_source: str) -> bool:\n",
    "    \"\"\"Checks if the right page is loaded\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    page_source : str\n",
    "        str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        bool\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(page_source, \"lxml\")\n",
    "    notes = soup.find_all(\"p\", class_=\"prewrapped-text\")\n",
    "    return len(notes) > 1\n",
    "\n",
    "\n",
    "def extract_notes_from_page_source(page_source: str) -> str:\n",
    "    \"\"\"Extracts and cleans notes/comments from log page source\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    page_source : str\n",
    "        str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        str\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(page_source, \"lxml\")\n",
    "    notes = soup.find_all(\"p\", class_=\"prewrapped-text\")\n",
    "    notes_lst = [n.get_text().replace(\"\\n\", \"  \") for n in notes]\n",
    "    return \"\\n\\n\".join([notes_lst[0]] + notes_lst[1:][::-1])\n",
    "\n",
    "\n",
    "def scrape_with_bsoup(ticket_str: str) -> str:\n",
    "    \"\"\"Opens log, extracts/cleans notes/comments, format and return\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ticket_str : str\n",
    "        str - \"<ticket_num> <employee_id> - \"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        str - \"<employee_id> - <notes/comments>  <url>\"\n",
    "    \"\"\"\n",
    "    note_start = ticket_str.split(\" \", 1)[-1]\n",
    "    ticket_num = ticket_str.split(\" \", 1)[0]\n",
    "    search_ticket_num(ticket_num)\n",
    "    view_log()\n",
    "    harmony_url = \"\"\n",
    "    while \"cmLogViewPage\" not in harmony_url:\n",
    "        time.sleep(0.1)\n",
    "        harmony_url = driver.current_url\n",
    "        page_source = driver.page_source\n",
    "\n",
    "    test_page_source = test_page_source_ok(page_source)\n",
    "    while test_page_source == False:\n",
    "        time.sleep(0.1)\n",
    "        page_source = driver.page_source\n",
    "        test_page_source = test_page_source_ok(page_source)\n",
    "\n",
    "    result = extract_notes_from_page_source(page_source)\n",
    "    return f\"{note_start}\\n\\n{result}\\n{harmony_url}\"\n",
    "\n",
    "\n",
    "def scraped_notes_to_df(input_ticket_strs: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"For list of ticket numbers, returns formatted details and add to dataframe - see `scrape_with_bsoup`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_ticket_strs : list[str]\n",
    "        list[str]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    result_df = pd.DataFrame(columns=[\"ticket_str\", \"details\"])\n",
    "\n",
    "    for ticket_str in input_ticket_strs:\n",
    "        if \"updated\" in ticket_str:\n",
    "            notes = \"updated\"\n",
    "        else:\n",
    "            notes = scrape_with_bsoup(ticket_str=ticket_str)\n",
    "        result_df.loc[len(result_df)] = list((ticket_str, notes))\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def load_edited_details(_=None) -> list[str]:\n",
    "    \"\"\"Result of `scraped_notes_to_df` gets exported to excel and manual edits are made, if needed. This function loads the edited file and cleans up the details column to add back to the log tracker.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    _ : ...\n",
    "        disregard\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        list[str]\n",
    "    \"\"\"\n",
    "\n",
    "    output_file = sorted([x for x in os.listdir() if x.lower().endswith(\".xlsx\")])[-1]\n",
    "    df = pd.read_excel(output_file)\n",
    "\n",
    "    details_list_cleaned = []\n",
    "    details_list = df[\"details\"].tolist()\n",
    "    for l in details_list:\n",
    "        t_list = l.split(\"\\n\")\n",
    "        clean_note = \"\\n\".join([x for x in t_list if x.strip() != \"-\"])\n",
    "        details_list_cleaned.append(clean_note)\n",
    "\n",
    "    return [\n",
    "        x.replace(\"\\n\", \"\").strip().replace(\"https:\", \"   https:\")\n",
    "        for x in details_list_cleaned\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
